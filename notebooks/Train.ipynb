{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerating your code on shiney new Tesla P100-PCIE-16GB GPU.\n"
     ]
    }
   ],
   "source": [
    "import magnet as mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captioner.nlp import get_nlp\n",
    "from captioner.hparams import (vocab_size, caption_idx, shuffle, hidden_size,\n",
    "                               num_layers, rnn_type, learning_rate,iterations,\n",
    "                               epochs, save_every, write_every, optimizer)\n",
    "from captioner.data import get_training_dataloaders\n",
    "from captioner.model import Model\n",
    "from captioner.train import optimize\n",
    "from captioner.utils import get_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATA /= 'COCO'\n",
    "DIR_CHECKPOINTS = DIR_MAIN / 'checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SpaCy Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spaCy](../assets/spacy.png)\n",
    "\n",
    "We use an NLP library called [spaCy](spacy.io) for tokenizing and vectorizing the captions.\n",
    "\n",
    "This will make it easy for us to handle things like pretrained word embeddings, pruning and tokenizing easy.\n",
    "\n",
    "The ['en_core_web_lg'](https://spacy.io/models/en#en_core_web_lg) gets the corresponding _model_ from spaCy.\n",
    "It was trained as part of english multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = get_nlp('en_core_web_lg', vocab_size, DIR_CHECKPOINTS / 'vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of spaCy's word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = nlp.vocab.vectors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the DataSets into memory and get corresponding DataLoaders for the training and validation sets as a dictionary.\n",
    "\n",
    "The ```caption_idx``` is the index of the caption that will be generated by the DataLoader.\n",
    "If negative, it selects one at random for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader = get_training_dataloaders(DIR_DATA, caption_idx, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader['val']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the size of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = x[0].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model](../assets/model.png)\n",
    "Based on [this](https://arxiv.org/abs/1411.4555) paper by [Oriol Vinyals](https://ai.google/research/people/OriolVinyals), [Alexander Toshev](https://www.linkedin.com/in/alexander-toshev-9270726), [Samy Bengio](https://ai.google/research/people/bengio) and [Dumitru Erhan](http://www.dumitru.ca/).\n",
    "\n",
    "<br>\n",
    "\n",
    "Made famous by [this](https://arxiv.org/abs/1412.2306v2) paper by [Andrej Karpathy](https://www.linkedin.com/in/andrej-karpathy-9a650716) and [Li Fei-Fei](https://www.linkedin.com/in/fei-fei-li-4541247).\n",
    "<br>\n",
    "![Karpathy's Model](../assets/karpathy.png)\n",
    "\n",
    "The extracted features are treated as the initial hidden state of the RNN.\n",
    "In order to match the dimensionality, it's first sent through a Linear layer and reshaped.\n",
    "\n",
    "On the basis of this conditioning, the model generates it's hidden states which are further sent through a Linear layer of dimension ```vocab_size```.\n",
    "\n",
    "Thus, at each timestep, we have a score for each possible word.\n",
    "\n",
    "We treat this like a classification problem and use the categorical cross-entropy loss to match it to the desired _label_ at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(feature_dim, embedding_dim, hidden_size,\n",
    "              num_layers, rnn_type, vocab_size)\n",
    "\n",
    "device = 'cuda:0' if mag.device == 'cuda' else mag.device\n",
    "if (DIR_CHECKPOINTS / 'model.pt').exists():\n",
    "    model.load_state_dict(torch.load(DIR_CHECKPOINTS / 'model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When these papers were first published, Adam was not known.\n",
    "\n",
    "I've found good results using Adam with AMSGrad.\n",
    "None of the embellishments (like gradient clipping) were found to be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(optimizer)\n",
    "optimizer = optimizer(model.parameters(), learning_rate)\n",
    "if (DIR_CHECKPOINTS / 'optimizer.pt').exists():\n",
    "    optimizer.load_state_dict(torch.load(DIR_CHECKPOINTS / 'optimizer.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This object holds the history of training.\n",
    "history = {'iterations': 0, 'loss': [], 'val_loss': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimize(model, optimizer, history, dataloader, nlp, DIR_CHECKPOINTS,\n",
    "         epochs, iterations, save_every, write_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history['loss'], label='loss')\n",
    "plot(history['val_loss'], label='val_loss')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [perplexity](https://stats.stackexchange.com/questions/10302/what-is-perplexity) is simply the exponential of the cross-entropy.\n",
    "\n",
    "It can be roughly interpreted as the number of sides in a fair dice, which when rolled, would produce a sequence (caption) with the same entropy as ours.\n",
    "\n",
    "The fewer the better (obviously)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(np.exp(np.array(history['loss'])), label='perplexity')\n",
    "plot(np.exp(np.array(history['val_loss'])), label='val_perplexity')\n",
    "plt.yscale('log')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:captioner]",
   "language": "python",
   "name": "conda-env-captioner-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
